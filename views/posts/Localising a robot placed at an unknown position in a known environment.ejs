<html>
	<head>
		<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="  crossorigin="anonymous"></script>
		<script src = "/jquery-highlight.js"></script>
		<link href="/jquery.upvote.css" rel="stylesheet">
		<script src = "/jquery.upvote.js" type="text/javascript"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
		<link rel="stylesheet" href="/style.css"/>
		<script src="/createlinks.js"></script>
		<script src="/textaudit.js"></script>
		<script src="/PorterStemmer1980.min.js"></script>
		<script src="/highlight.js"></script>
		<title id = 'pagetitle'>Localising a robot placed at an unknown position in a known environment
		</title>
	</head>
	<body id = 'pagebody'>
		<div id = "loginmodals"></div>
		<div id = "issuemodals"></div>
		<div id = "highlight_tool"></div>
		<div id = "reward_tool"></div>
		<div id = "comment_tool"></div>
		<div class = "container">
			<header>
				<h1>Just Another Discussion Forum</h1>
			</header>
			<div class="topnav" id="myTopnav">
				<a href="/home">Home</a>
				<a href = "#issueModal" data-toggle="modal" style = "float:right">Report Issue</a>
			</div>
			<div class = "content">
			<div id = "ques-10330" class = "post">
			<h2>Question</h2>
			<div id="vote-10330" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">1</span>
				<a class="downvote"></a>
				<a class="star"></a>
				<p>Views :: 274</p>
			</div>
			<form id = "questionpostsform" method="GET" action = "/ask">
				<input type="submit" id = "quesbtn" class="btn btn-primary btn-lg" value="Ask Question">
			</form>
				<h2>Localising a robot placed at an unknown position in a known environment</h2>
<p>I am a third-year electrical engineering student and am working on an intelligent autonomous robot in my summer vacations.</p>

<p>The robot I am trying to make is supposed to be used in rescue operations. The information I would know is the position of the person (the coordinates of the person in a JSON file) to be rescued from a building on fire. I would also know the rooms of the building from a map, but I don't know where the robot may be placed inside the building to start the rescue operation.</p>

<p>That means I have to localise the robot placed at an unknown position in a known environment, and then the robot can plan its path to the person who has to be rescued. But, since this is not my domain I would like you to guide me on what is the best method for localising given that I can use an IMU ( or gyro, accelerometer, magnetometer) and ultrasonic sensors to do the localising job. I cannot use a GPS module or a camera for this purpose. </p>

<p>I, however, do know how to do path planning.</p>

<p>As far as my research on the Internet is concerned I have found a method called "Kalman filtering" that maybe can do the localising job. But there are I think some other filtering methods as well. Which one should I use? Or is there any other simpler/better method out there of which I don't know yet?</p>

<p>I am also attaching the map of the building which is known to me.</p>

<p><a href="https://i.stack.imgur.com/QDoUf.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/QDoUf.png" alt="enter image description here"></a></p>

<p>Edit:</p>

<p>The terrain is flat, and I would like to know where the robot is on the map like at coordinate 0,4 etc.</p>

			</div>
			<div class = "userinfosection"  id = "userinfo-10330" data-toggle = "popover">
				<p>user name : Muhammad Faique Shakeel</p>
				<p> user reputation : 30</p>
				<p class = "tagcontent" id = "usertaginfo-10330">{'None': 0, 'accelerometer': 1, 'localization': 4, 'arduino': 3, 'mapping': 3, 'planning': 1, 'imu': 1, 'mobile-robot': 4, 'motion-planning': 2, 'gyroscope': 1}</p>
			</div><br>
			<br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-10330">Load Comments</button></br>
			<div id = "commentsection-10330" class = 'collapse'>
			<div id = "comment-18517" class = "comment">
				<p>Is the terrain flat? Do you care where you are globally? For instance, do you want to know you are at (4,6) on the image you have posted, or can you define (0,0) as your starting position? Kalman filtering will help, but really you want to use SLAM, which Kalman filtering is a part of. Your choice of KF/SLAM algorithm depends on which sensors and observations you have available to you. If you give us more information we may be able to suggest which variant of SLAM you need. I highly recommend using ROS, see http://wiki.ros.org/robot_localization</p>
			</div>
			<div id = "comment-18526" class = "comment">
				<p>@Gouda Yes, the terrain is flat.Yes, I want to know that I am at (4,6) on the image, but my starting position will be unknown. I can start from anywhere in the grid. As stated in the question I have IMU and ultrasonic sensors......</p>
			</div>
			<div id = "comment-18768" class = "comment">
				<p>On stack exchange, it is better to edit your question to add information requested in comments, rather than adding more comments @MuhammadFaiqueShakeel . Comments are for helping to improve questions and answers, and are distracting, so we try to keep them to a minimum. If all of the information needed to answer the question is contained within it, the comments can be tidied up (deleted). Comments should be considered ephemeral, any comment which no longer actively helps to improve a question or answer may be deleted at any time.</p>
			</div>
			<div id = "comment-18771" class = "comment">
				<p>@MarkBooth Alright, Ill edit the question. Thanks a lot for letting me know this!</p>
			</div>
			<div id = "comment-18773" class = "comment">
				<p>Thanks @MuhammadFaiqueShakeel, I hope that you and your team mate find the answers here useful.</p>
			</div>
			<div id = "comment-19333" class = "comment">
				<p>Why did you withheld the fact that this is a task from a competition? http://www.nerc.com.pk/Categories/Indigenous?AspxAutoDetectCookieSupport=1</p>
			</div>
			<div id = "comment-19335" class = "comment">
				<p>That is because I am not participating in this competition. This is just a side project that I started doing in my summer vacations. I just wanted to do something good, not necessarily exactly what the competition requires.</p>
			</div>
			</div>
				<textarea id = "speech-10330" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-10330">
					<img id="start_img-10330" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-10330">Comment</button>

<h1>Answers</h1>
			<br><div id = "ans-10331"  class = "post">
				<h2>Answer</h2>
			<div id="vote-10331" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">3</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>The problem is that you can't apply path planning until you know where the robot is in the global coordinate frame. There are many localization techniques, and each has its pros/cons; I have used Particle Filtering for a very similar localization task. Extensive coverage of particle filtering is given by Sebastian Thrun in his book <em>Probabilistic Robotics</em>--see chapter 8. There are advantages of particle filtering over Kalman Filtering (and the other way around), but the nice thing about particle filtering is that you can use raw measurements directly, it accepts measurement noise with any distribution, it can be used for global localization, it doesn't rely on a discretization of the world (e.g. a grid), and it is relatively simple to implement. </p>

<p>The algorithm presented by Thrun is Monte Carlo Localization (MCL). Prerequisites for the algorithm are that you have a model for the motion of your robot (this could be noisy unicycle dynamics) and a measurement model of your sensor--in your case, the ultrasonic sensor is a noisy beam sensor. See <a href="https://robotics.stackexchange.com/posts/10175/edit">my previous post</a> about ultrasonic sensors and measurement models. For the particle filter, you won't really need the IMU data, but you can incorporate it to improve your localization results; I will assume that you won't do this. </p>

<p>The MCL algorithm is summarized but the following pseudo-code:</p>

<ol>
<li>$\bar{X}=X=\varnothing$</li>
<li><p>For m=1 to M particles, do:</p>

<p>i. $x_t^{[m]}$=sample_motion_model($u_t,x_{t-1}^{[m]}$)</p>

<p>ii. $w_t^{[m]}$=sample_measurement_model($z_t,x_t^{[m]},m$)</p>

<p>iii. $\bar{X_t}+=\langle x_t^{[m]}, w_t^{[m]}\rangle$</p></li>
<li><p>For m=1 to M particles, do:</p>

<p>i. sample particle $i$ with probability proportional to $w_t^[i]$</p>

<p>ii. add $x_t^{[i]}$ to $X_t$</p></li>
<li><p>Return $X_t$</p></li>
</ol>

<p>$X_t$ is the set of M particles $\{x_t^{[1]},x_t^{[2]},...,x_t^{[M]}\}.$ $u_t$ is the action taken at time $t$, $z_t$ is the measurement taken at time $t$, $x_t^{[m]}$ is a particle representing the state of the robot at time $t$, and $w_t^{[m]}$ is the weight of particle $m$ at time $t$. The bar notation indicates a belief prior to incorporating the measurement, just after executing the action.</p>

<p>In words, particle filtering works like this: throw out a bunch of particles, see how good they are based on what the robot has just done and based on what the robot observes, then pick the best particles and repeat. For particle filtering, you need to use a sufficiently large number of particles, and there are numerous techniques that can be used to improve performance and accuracy. Also, you need to know some math to go through the proof, but it is straightforward. </p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-10331" data-toggle = "popover">
				<p>user name : NBCKLY</p>
				<p> user reputation : 741</p>
				<p class = "tagcontent" id = "usertaginfo-10331">{'None': 44, 'roomba': 4, 'irobot-create': 4, 'arduino': 2}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-10331" class = 'collapse'>
			</div>
				<textarea id = "speech-10331" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-10331">
					<img id="start_img-10331" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-10331">Comment</button>
			<br><div id = "ans-10332"  class = "post">
				<h2>Answer</h2>
			<div id="vote-10332" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">2</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>There are many tactics for localization in a <strong>known</strong> environment. the most popular ones are the Filtering methods which include Kalman filtering and <a href="https://en.wikipedia.org/wiki/Particle_filter" rel="nofollow">Particle filtering</a>. Nowadays the second one is the most efficient and most widely used in this kind of situations. A good starting point for learning about localization techniques and the intuition behind them is this <a href="https://www.udacity.com/course/artificial-intelligence-for-robotics--cs373" rel="nofollow">Robotics course on Udacity</a> by Sebastian Thrun.</p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-10332" data-toggle = "popover">
				<p>user name : bergercookie</p>
				<p> user reputation : 155</p>
				<p class = "tagcontent" id = "usertaginfo-10332">{'rangefinder': 0, 'None': 5, 'slam': 0, 'laser': 0}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-10332" class = 'collapse'>
			</div>
				<textarea id = "speech-10332" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-10332">
					<img id="start_img-10332" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-10332">Comment</button>
			<br><div id = "ans-10337"  class = "post">
				<h2>Answer</h2>
			<div id="vote-10337" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">1</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>Firstly, to solve your problem in full would be a rather large post so I will focus on the methodology that you should follow.</p>

<p>As others have said, you would use some kind of filtering method to solve your problem; particle filtering, Kalman filtering, they are all the same thing but different variants that have different strengths. You could also use Markov Model methods that operate in discrete space rather than continuous space.</p>

<p>Firstly let's define the task: 3D (X, Y positions and yaw angle) localisation using an <em>a priori</em> map. This is different from SLAM (Simultaneous Localisation and Mapping) because you already have a map.
That being said, you could probably use <a href="http://www.mrpt.org/List_of_SLAM_algorithms" rel="nofollow">an existing slam algorithm</a> with a high-belief prior set by the map you have.</p>

<p>This leads to the definition of the states you are interested in (called the <em>state vector</em>):
$$\mathbf{x}_{k} = \big[ \mathbf{p}^\top, \mathbf{v}^\top, \psi \big]^\top$$
Where $\mathbf{x_k}$ is the state vector at discrete time-step $k$, $\mathbf{p}$ and $\mathbf{v}$ are the position and velocity, and $\psi$ is the yaw angle of the robot (all measured with respect to, and expressed in a global frame $\{G\}$). Velocity is added there because it is necessary for the prediction stage of the filter.</p>

<p>Second let's define the observations you can make (I exclude sensor measurements unnecessary for solving this 3DOF problem):</p>

<ul>
<li>Range measurements of the relative position to the wall ahead of the robot: $y_u(\mathbf{x_k})$</li>
<li>Inertial measurements of the motion of the body:

<ul>
<li>Acceleration (2 axes, x and y): $\mathbf{a}_k$</li>
<li>Angular rotation rate (1 axis, z) $\mathbf{\omega}_k$</li>
<li>Magnetic field strength (1 axis, z) $m_k$</li>
</ul></li>
<li>All measurements are made in the body frame $\{B\}$ which is attached to the IMU (note there is a transform between the ultrasound and body which I am not addressing, but should be addressed in an actual solution).</li>
</ul>

<p>Now the issue is how do you use a filtering methodology to localise your robot? 
Regardless of your choice of filter you will need a model that describes how the robot evolves through time (the <em>process model</em>). 
Then you need a <strong>measurement model for each of your sensors</strong>, which describes what measurement is expected given an arbitrary state $\mathbf{x}$ of the robot.</p>

<p>For such a problem, your measurement models would describe (1) the ultrasound range, (2) the accelerometer, (3) the rate gyro, (4) the magnetometer.</p>

<p>Because of the high update rates of the IMU it is commonly used in the process model directly so that the update stage of the filter is not used too frequently (it is more computationally expensive than the predict stage). I'll refer you to equations (3) - (8) in <a href="http://www-users.cs.umn.edu/~stergios/papers/TRO_08-IMU-Camera-calibration.pdf" rel="nofollow">this paper</a> for this process model (in this application there is no need for quaternions so I'd advise to use Euler angle representations of the orientation instead). </p>

<p>Additionally, you must model the bias states in the IMU, which then adds another two states to your state vector:
$$\mathbf{x}_{k} = \big[ \mathbf{p}^\top, \mathbf{v}^\top, \psi, \mathbf{b}_a^\top, b_\omega \big]^\top$$
Where $\mathbf{b}_a$ and $b_\omega$ are the biases in the accelerometers and gyroscope, respectively.</p>

<p>The measurement model for the magnetometer can be found in equation 5.10 in <a href="http://folk.ntnu.no/tomgra/Diplomer/Brembo.pdf" rel="nofollow">this thesis</a>.</p>

<p>Let's simplify your measurement model for your ultrasound, and pretend it is a laser range finder that simply returns the distance of the object (wall) it is pointing to. I assume you can do the calculation to convert the pulse times to distance. Your model is then:
$$y_u(\mathbf{x}_k) = |\mathbf{p}_{w,B}^B|_2 = |R^B_G(\mathbf{p}_{w,G}^G - \mathbf{p}_{B,G}^G)|_2$$
Where $ \mathbf{p}_{w,B}^B $ is the <strong>p</strong>osition of the <strong>w</strong>all that is being pointed to, with respect to (superscript) and measured from (subscript) the $\{B\}$ frame. $R^B_G$ is the rotation matrix that rotates a vector in the $\{G\}$ frame to the $\{B\}$ frame, and $\mathbf{p}_{B,G}^G$ is the position of the $\{B\}$ frame with respect to and expressed in the $\{G\}$ frame (which is the robot location represented by $p$ in the state vector).</p>

<p>You'll have to think about how to parameterize and calculate $\mathbf{p}_{w,G}^G$ (which is a function of the wall geometry, $p$ and $\psi$), I would think it would work with a look-up table or a solution to a set of line intersection equations representing the range beam and the walls. Either way it is discontinuous and nonlinear so this supports the use of a particle filter over a Kalman-based filter. You could possibly have a different measurement model for each wall if you really want to use a Kalman Filter, but that introduces a new data-association problem which is non-trivial.</p>

<p>I hope this plus NBCKLY's PF psuedocode gets you on your way.</p>

<p>A good <a href="https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-696.pdf" rel="nofollow">resource</a> on IMU models and noise.</p>

<p>Maybe of interest is <a href="http://user.it.uu.se/~thosc112/kihlbergtks2014.pdf" rel="nofollow">this</a> use of highly non-linear maps in PF's.</p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-10337" data-toggle = "popover">
				<p>user name : Gouda</p>
				<p> user reputation : 632</p>
				<p class = "tagcontent" id = "usertaginfo-10337">{'control': 0, 'None': 39, 'computer-vision': 1, 'calibration': 1, 'cameras': 1, 'kalman-filter': 0, 'jacobian': 0}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-10337" class = 'collapse'>
			</div>
				<textarea id = "speech-10337" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-10337">
					<img id="start_img-10337" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-10337">Comment</button>
			</div>
			<div id = "resourcestab" class = "resourcestab">
				<ul class="nav nav-tabs">
					<li class="active"><a data-toggle="tab" href="#resources">Resources</a></li>
					<li><a data-toggle="tab" href="#highlights">Highlights</a></li>
				</ul>
					<div class="tab-content">
						<div id="resources" class="tab-pane fade in active">
							<h3>Links from the Page</h3>
							<div id = "resourcescontent"></div>
						</div>
						<div id="highlights" class="tab-pane fade">
							<h3>Highlights</h3>
							<div id = "highlightcontent"></div>
						</div>
			</div>
			</div>
			<footer>Moore & Peps collaboration.</footer>
	</div>
	<script src="/post.js"></script>
	<script type="text/javascript">
		$("#loginmodals").load("/loginModal.html");
		$("#issuemodals").load("/issueModal.html");
		$("#highlight_tool").load("/highlight_tool.html");
		$("#comment_tool").load("/comment_tool.html");
		$("#reward_tool").load("/reward_tool.html");
		checkLoggedInUser()
		var content = $('.content').html();
		populateResources(content)
		getHighlights()
		setOnLinksHover()
	</script>
	<script src="/media.js"></script>
	<script src="/vote.js"></script>
	<script src="/managefunction.js"></script>
	</body>
</html>