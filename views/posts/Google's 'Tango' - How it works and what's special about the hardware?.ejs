<html>
	<head>
		<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="  crossorigin="anonymous"></script>
		<script src = "/jquery-highlight.js"></script>
		<link href="/jquery.upvote.css" rel="stylesheet">
		<script src = "/jquery.upvote.js" type="text/javascript"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
		<link rel="stylesheet" href="/style.css"/>
		<script src="/createlinks.js"></script>
		<script src="/textaudit.js"></script>
		<script src="/PorterStemmer1980.min.js"></script>
		<script src="/highlight.js"></script>
		<title id = 'pagetitle'>Google's 'Tango' - How it works and what's special about the hardware?
		</title>
	</head>
	<body id = 'pagebody'>
		<div id = "loginmodals"></div>
		<div id = "issuemodals"></div>
		<div id = "highlight_tool"></div>
		<div class = "container">
			<header>
				<h1>Just Another Discussion Forum</h1>
			</header>
			<div class="topnav" id="myTopnav">
				<a href="/home">Home</a>
				<a href = "#issueModal" data-toggle="modal" style = "float:right">Report Issue</a>
			</div>
			<div class = "content">
			<div id = "ques-12089" class = "post">
			<h2>Question</h2>
			<div id="vote-12089" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">0</span>
				<a class="downvote"></a>
				<a class="star"></a>
				<p>Views :: 91</p>
			</div>
			<form id = "questionpostsform" method="GET" action = "/ask">
				<input type="submit" id = "quesbtn" class="btn btn-primary btn-lg" value="Ask Question">
			</form>
				<h2>Google's 'Tango' - How it works and what's special about the hardware?</h2>
<p>I'm looking for a good breakdown and explanation of Google's 'Tango' AR platform.  Specifically how the hardware works together to generate depth maps and the SDK's use of it.</p>

<p>I know the hardware composes of a fisheye lens camera and an RGB-I camera.  I am only familiar with stereo vision with identical cameras and disparity maps, I am thinking the different lenses and camera elements make it easier to distinguish variations in the environment but must have some very special (and proprietary) algorithms.  However, there must actually some special hardware and dedicated chipsets for processing the depth map to take the burden off the CPU/GPU?</p>

<p>Also, for the AR software implementation, I assume the SDK has some GPU utilization built into it like OpenCL or CUDA (but specific for the Adreno GPU).  Does it simply use OpenCL (this is supported by the Adreno GPU) or does it have something proprietary from Google similar to CUDA for the nVidia chipsets?</p>

<p>Basis for the question - I work with OpenCV some and am experimenting with stereo vision applications, but would like to move on to developing apps for specialized hardware and this sounds like the right (maybe only?) platform.</p>

			</div>
			<div class = "userinfosection"  id = "userinfo-12089" data-toggle = "popover">
				<p>user name : NateGreco</p>
				<p> user reputation : 153</p>
				<p class = "tagcontent" id = "usertaginfo-12089">{'stereo-vision': 0, 'None': 4, 'computer-vision': 0, 'laser': 2, 'lidar': 2, 'opencv': 0, 'rangefinder': 2}</p>
			</div><br>
			<br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-12089">Load Comments</button></br>
			<div id = "commentsection-12089" class = 'collapse'>
			<div id = "comment-21430" class = "comment">
				<p>I'm not sure you're going to find a satisfactory answer to this question here. I would imagine that whatever Google wants to release about their device has already been made public, and whatever hasn't been released is probably proprietary.</p>
			</div>
			</div>
				<textarea id = "speech-12089" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-12089">
					<img id="start_img-12089" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-12089">Comment</button>

<h1>Answers</h1>
			<br><div id = "ans-12160"  class = "post">
				<h2>Answer</h2>
			<div id="vote-12160" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">1</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>I suspect, but don't know, that the Tango uses a variant of volumetric reconstruction using a Truncated Signed Distance Function (Good intro at <a href="http://www.cs.nyu.edu/courses/fall12/CSCI-GA.2945-001/dl/jiakai-slides.pdf" rel="nofollow noreferrer">http://www.cs.nyu.edu/courses/fall12/CSCI-GA.2945-001/dl/jiakai-slides.pdf</a>) </p>

<p>It uses structured IR light to obtain a dense depth map, projects these points back into 3-space as a point cloud, probably turns this into a mesh by triangulating it and then projects it into a TSDF volume representing the space being mapped.  </p>

<p>Marching Cubes or similar algorithm can then be used to extract the 0 crossing of this isosurface into a mesh.</p>

<p>Given that the Tango seems to bee able to map quite large areas, I would assume that either the mapping resolution is quite coarse or else Google have implemented a streaming algorithm to move the volumetric reconstruction into and out of GPU memory.</p>

<p>The seminal paper here is KinectFusion (<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ismar2011.pdf" rel="nofollow noreferrer">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ismar2011.pdf</a>) which describes how this was done with a Kinect using depth only data.</p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-12160" data-toggle = "popover">
				<p>user name : Dave Durbin</p>
				<p> user reputation : 26</p>
				<p class = "tagcontent" id = "usertaginfo-12160">{'None': 1}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-12160" class = 'collapse'>
			</div>
				<textarea id = "speech-12160" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-12160">
					<img id="start_img-12160" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-12160">Comment</button>
			</div>
			<div id = "resourcestab" class = "resourcestab">
				<ul class="nav nav-tabs">
					<li class="active"><a data-toggle="tab" href="#resources">Resources</a></li>
					<li><a data-toggle="tab" href="#summary">Summary</a></li>
				</ul>
					<div class="tab-content">
						<div id="resources" class="tab-pane fade in active">
							<h3>Resources</h3>
							<div id = "resourcescontent"></div>
						</div>
						<div id="summary" class="tab-pane fade">
							<h3>Summary</h3>
							<div id = "summarycontent"></div>
						</div>
			</div>
			</div>
			<footer>Moore & Peps collaboration.</footer>
	</div>
	<script src="/post.js"></script>
	<script type="text/javascript">
		$("#loginmodals").load("/loginModal.html");
		$("#issuemodals").load("/issueModal.html");
		$("#highlight_tool").load("/highlight_tool.html");
		checkLoggedInUser()
		var content = $('.content').html();
		populateResources(content)
		getHighlights()
		setOnLinksHover()
	</script>
	<script src="/media.js"></script>
	<script src="/vote.js"></script>
	<script src="/managefunction.js"></script>
	</body>
</html>