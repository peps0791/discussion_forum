<html>
	<head>
		<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="  crossorigin="anonymous"></script>
		<script src = "/jquery-highlight.js"></script>
		<link href="/jquery.upvote.css" rel="stylesheet">
		<script src = "/jquery.upvote.js" type="text/javascript"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
		<link rel="stylesheet" href="/style.css"/>
		<script src="/createlinks.js"></script>
		<script src="/textaudit.js"></script>
		<script src="/PorterStemmer1980.min.js"></script>
		<script src="/highlight.js"></script>
		<title id = 'pagetitle'>it's worth to make a line follower using a raspberry pi and a web cam?
		</title>
	</head>
	<body id = 'pagebody'>
		<div id = "loginmodals"></div>
		<div id = "issuemodals"></div>
		<div id = "highlight_tool"></div>
		<div class = "container">
			<header>
				<h1>Just Another Discussion Forum</h1>
			</header>
			<div class="topnav" id="myTopnav">
				<a href="/home">Home</a>
				<a href = "#issueModal" data-toggle="modal" style = "float:right">Report Issue</a>
			</div>
			<div class = "content">
			<div id = "ques-4385" class = "post">
			<h2>Question</h2>
			<div id="vote-4385" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">1</span>
				<a class="downvote"></a>
				<a class="star"></a>
				<p>Views :: 3547</p>
			</div>
			<form id = "questionpostsform" method="GET" action = "/ask">
				<input type="submit" id = "quesbtn" class="btn btn-primary btn-lg" value="Ask Question">
			</form>
				<h2>it's worth to make a line follower using a raspberry pi and a web cam?</h2>
<p>I wonder if this would be a competitive robot compared with one made with a traditional approach using a microcontroller and infrared sensors. I suppose that raspberry can perform an edge detection to tell the dynamic of the line far away, much more that the infrared sensor, but how fast can the raspberry do this process? should be a relative simple process in terms of computational requirements , an edge detection in a high contrast arena. Probably the bigger issue would be get the relative position of the robot respect to the line, may be a combination of the camera with some infrared sensors would work better, and what about the size? the robot will be significantly bigger when is used a camera and a raspberry for the control.</p>

			</div>
			<div class = "userinfosection"  id = "userinfo-4385" data-toggle = "popover">
				<p>user name : user2720241</p>
				<p> user reputation : 9</p>
				<p class = "tagcontent" id = "usertaginfo-4385">{'None': 0, 'line-following': 1, 'raspberry-pi': 1}</p>
			</div><br>
			<br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-4385">Load Comments</button></br>
			<div id = "commentsection-4385" class = 'collapse'>
			<div id = "comment-14975" class = "comment">
				<p>Define "competitive".  By what metric do you measure "competitiveness"?</p>
			</div>
			</div>
				<textarea id = "speech-4385" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-4385">
					<img id="start_img-4385" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-4385">Comment</button>

<h1>Answers</h1>
			<br><div id = "ans-4387"  class = "post">
				<h2>Answer</h2>
			<div id="vote-4387" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">3</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>This may be overkill, but <a href="http://web.mit.edu/Misti/mit-brazil/forum/Triantafyllou.pdf" rel="nofollow noreferrer">some of the past work I was involved in</a> was trying to detect a vertical line (a pipe) in the camera's field of vision, and navigate relative to it.</p>

<p><a href="http://web.mit.edu/Misti/mit-brazil/forum/Triantafyllou.pdf" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/CZuDHm.png" alt="Detecting a pipe with computer vision"></a></p>

<p>The process was as follows:</p>

<ol>
<li>Pick a threshold value, and split the image into black and white</li>
<li>Perform <a href="http://en.wikipedia.org/wiki/Canny_edge_detector" rel="nofollow noreferrer">Canny edge detection</a> on the image</li>
<li>Use a <a href="http://en.wikipedia.org/wiki/Hough_transform" rel="nofollow noreferrer">Hough transform</a> to find the strongest lines in the image, and consider those to be the boundaries of the vertical strip you're looking for</li>
<li>Adjust for the perceived width (indicating distance -- you won't need this) and angle of the vertial strip in the image</li>
</ol>

<p>We <a href="https://github.com/ifreecarve/SGMOOS/blob/master/Instruments/iVision/HoughPipeFollow.cpp" rel="nofollow noreferrer">used OpenCV to do this</a>.  </p>

<p>We didn't get very good results at full camera resolution; The very pixellated lines in the image above were from downsampling the source video frame (by a factor of 3 in both directions, I think... so 1/9 the number of pixels to worry about).  This allowed us to process frames fast enough for it to be useful.  Also, the point of the initial threshold step was to speed up the Canny process -- fewer lines to find.</p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-4387" data-toggle = "popover">
				<p>user name : Ian</p>
				<p> user reputation : 9640</p>
				<p class = "tagcontent" id = "usertaginfo-4387">{'planning': 10, 'None': 809, 'power': 1, 'algorithm': 10, 'battery': 1, 'slam': 7, 'coverage': 10, 'mobile-robot': 9, 'sensors': 9}</p>
			</div><br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-4387">Load Comments</button></br>
			<div id = "commentsection-4387" class = 'collapse'>
			<div id = "comment-6959" class = "comment">
				<p>Thanks, it looks pretty interesting, I like it, did you use a raspberry pi? I would like to get and idea of the distance, to speed up, or speed down when the robot is far or close to the hard points of the arena</p>
			</div>
			<div id = "comment-6962" class = "comment">
				<p>We were using this board, which even though several years old is apparently still faster than the Rpi: http://adl-usa.com/products/detail/19/adls15pc</p>
			</div>
			<div id = "comment-6965" class = "comment">
				<p>I see, it really looks more powerful, I was thinking about make a edge detection and then a correlation of the image with some model curves like a really close curve or a straight segment of the track  to know how the arena is in the next point, It would be this a reasonable approach? How much time could take to the raspberry do such a thing? I mean the correlation of an 320 240 image, I read that the raspberry can make the edge detection in a speed of about 7.7 to 17.5 fps: http://ryanmessina.wordpress.com/2013/06/10/performance-of-raspberry-pi-with-opencv/</p>
			</div>
			<div id = "comment-6967" class = "comment">
				<p>Unfortunately there isn't a good way to guess the performance without trying.  There are surprising differences in performance from subtle changes in the code, and what order various operations happen in.</p>
			</div>
			<div id = "comment-14938" class = "comment">
				<p>Ian is correct. You can't really tell if a RasPi will be good for the job until you do it yourself, or talk with someone who has tried it already. My gut instinct is that it won't be powerful enough. Are you trying to use a RasPi for a reason - already have one? Because there are embedded boards out there that are built for image processing.</p>
			</div>
			</div>
				<textarea id = "speech-4387" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-4387">
					<img id="start_img-4387" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-4387">Comment</button>
			<br><div id = "ans-9079"  class = "post">
				<h2>Answer</h2>
			<div id="vote-9079" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">2</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>I did a project based on RPi2 + Pi-Camera + ROS jade + OpenCV to make a line following rover. Two methods are used, one is to find contour of the track, the other is to use Hough-transform for edge detection. Under well-controlled environment (even light sources, less noises, etc.) the performance is good, and I use RANSAC to find preferred edges under noisy environment. Pi-Camera is set to capture 320x240 RGB in 30fps. I overclock my RPi2 to 1.0Ghz, finding contour can process frames in 18-23 fps, and hough-transform is about 17fps (in a bit noisy environment.) For these two methods, Canny filter and Hough transform is the major bottleneck. I built this as a test platform, a cheap rover chassis is used with 2 geared DC motors. My codes in github: <a href="https://github.com/alexhuang888/roscar" rel="nofollow">https://github.com/alexhuang888/roscar</a></p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-9079" data-toggle = "popover">
				<p>user name : Alex Huang</p>
				<p> user reputation : 31</p>
				<p class = "tagcontent" id = "usertaginfo-9079">{'None': 2, 'ros': 2, 'alljoyn': 2}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-9079" class = 'collapse'>
			</div>
				<textarea id = "speech-9079" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-9079">
					<img id="start_img-9079" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-9079">Comment</button>
			</div>
			<div id = "resourcestab" class = "resourcestab">
				<ul class="nav nav-tabs">
					<li class="active"><a data-toggle="tab" href="#resources">Resources</a></li>
					<li><a data-toggle="tab" href="#summary">Summary</a></li>
				</ul>
					<div class="tab-content">
						<div id="resources" class="tab-pane fade in active">
							<h3>Resources</h3>
							<div id = "resourcescontent"></div>
						</div>
						<div id="summary" class="tab-pane fade">
							<h3>Summary</h3>
							<div id = "summarycontent"></div>
						</div>
			</div>
			</div>
			<footer>Moore & Peps collaboration.</footer>
	</div>
	<script src="/post.js"></script>
	<script type="text/javascript">
		$("#loginmodals").load("/loginModal.html");
		$("#issuemodals").load("/issueModal.html");
		$("#highlight_tool").load("/highlight_tool.html");
		checkLoggedInUser()
		var content = $('.content').html();
		populateResources(content)
		getHighlights()
		setOnLinksHover()
	</script>
	<script src="/media.js"></script>
	<script src="/vote.js"></script>
	<script src="/managefunction.js"></script>
	</body>
</html>