<html>
	<head>
		<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="  crossorigin="anonymous"></script>
		<script src = "/jquery-highlight.js"></script>
		<link href="/jquery.upvote.css" rel="stylesheet">
		<script src = "/jquery.upvote.js" type="text/javascript"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
		<link rel="stylesheet" href="/style.css"/>
		<script src="/createlinks.js"></script>
		<script src="/textaudit.js"></script>
		<script src="/PorterStemmer1980.min.js"></script>
		<script src="/highlight.js"></script>
		<title id = 'pagetitle'>Real-time camera localisation in known environment
		</title>
	</head>
	<body id = 'pagebody'>
		<div id = "loginmodals"></div>
		<div id = "issuemodals"></div>
		<div id = "highlight_tool"></div>
		<div class = "container">
			<header>
				<h1>Just Another Discussion Forum</h1>
			</header>
			<div class="topnav" id="myTopnav">
				<a href="/home">Home</a>
				<a href = "#issueModal" data-toggle="modal" style = "float:right">Report Issue</a>
			</div>
			<div class = "content">
			<div id = "ques-7841" class = "post">
			<h2>Question</h2>
			<div id="vote-7841" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">2</span>
				<a class="downvote"></a>
				<a class="star"></a>
				<p>Views :: 561</p>
			</div>
			<form id = "questionpostsform" method="GET" action = "/ask">
				<input type="submit" id = "quesbtn" class="btn btn-primary btn-lg" value="Ask Question">
			</form>
				<h2>Real-time camera localisation in known environment</h2>
<p>I am young researcher/developer coming from different (non-robotic) background and I did some research on camera localisation and I came to the point, where I can say that I am lost and I would need some of your help.</p>

<p>I have discovered that there is a lot of SLAM algorithms which are used for robots etc. As far as I know they are all in unknown environments. But my situation is different.</p>

<p>My problems and idea at the same time is:</p>

<ol>
<li>I will be placed in an known room/indoor environment (dimensions would be known)</li>
<li>I would like to use handheld camera</li>
<li>I can use predefined landmarks if they would help. In my case, I can put some " unique stickers" on the walls at predefined positions if that would help in any way for faster localisation.</li>
<li>I would like to get my camera position (with its orientation etc) in realtime(30 Hz or faster).</li>
</ol>

<p>For beginning I would like to ask which SLAM algorithm is the right one for my situation or where to start. Or do you have any other suggestions how to get real time camera positions inside of the known room/environment. It must be really fast and must allow fast camera movements. Camera would be on person and not on robot.</p>

<p>thank you in advance.</p>

			</div>
			<div class = "userinfosection"  id = "userinfo-7841" data-toggle = "popover">
				<p>user name : Excalibur</p>
				<p> user reputation : 11</p>
				<p class = "tagcontent" id = "usertaginfo-7841">{'None': 0, 'slam': 2, 'real-time': 2, 'localization': 2}</p>
			</div><br>
			<br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-7841">Load Comments</button></br>
			<div id = "commentsection-7841" class = 'collapse'>
			<div id = "comment-14109" class = "comment">
				<p>Oops just realized this question is from a long time ago.</p>
			</div>
			</div>
				<textarea id = "speech-7841" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-7841">
					<img id="start_img-7841" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-7841">Comment</button>

<h1>Answers</h1>
			<br><div id = "ans-7848"  class = "post">
				<h2>Answer</h2>
			<div id="vote-7848" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">2</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>As a matter of fact, if the environment is known a priori, then you don't need SLAM. It is a matter of localization problem which is simpler than SLAM in the sense that the map is given, therefore you don't need to estimate the map. In  <a href="http://www.probabilistic-robotics.org/" rel="nofollow">Probabilistic Robotics</a> book chapter 7, the localization problem is addressed and they use probabilistic methods for the estimation process. They use 2D laser sensor. In your case, the heavy load is the vision part (i.e. extracting meaningful information from frames), other than that, you need an algorithm for the estimation process (e.g. EKF or Partical Filter) and data association algorithm for the process of matching between the observed features and the features in the given map (i.e. assuming your map is of feature-based type).  </p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-7848" data-toggle = "popover">
				<p>user name : CroCo</p>
				<p> user reputation : 1040</p>
				<p class = "tagcontent" id = "usertaginfo-7848">{'control': 18, 'pid': 4, 'slam': 16, 'manipulator': 3, 'mobile-robot': 14, 'dynamics': 6, 'errors': 2, 'data-association': 1, 'kinematics': 3, 'matlab': 6, 'kalman-filter': 21, 'motion-planning': 3, 'None': 41, 'noise': 24, 'theory': 1, 'localization': 14, 'microcontroller': 5, 'mapping': 5, 'sensor-error': 1, 'sensors': 7, 'quadcopter': 8, 'ekf': 26, 'simulation': 1, 'motion': 3}</p>
			</div><br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-7848">Load Comments</button></br>
			<div id = "commentsection-7848" class = 'collapse'>
			<div id = "comment-11418" class = "comment">
				<p>OK ill give some more detailed informations for my two projects that are related - at least I think they are. 1) ill have environment made of canvas in shape of cylinder (radious between 6-12m and 4m height) with some projections going on. Next person walks into this environment and holds in his hand wooden stick(camera). As he points to canvas with his stick my question/requested data is position + orientation of the end of the stick. I was thinking about IR camera on "stick" and IR led diods/stickers since projection will be changing and can confuce SLAM if I understand the basics.</p>
			</div>
			<div id = "comment-11419" class = "comment">
				<p>Scenario 2) I would like to use pointcloud data from terrestrial laser scanner. For example I would scan my house from inside with laser scanner. This data would be as database/map for me. Next thing is that I would walk through my house with that stick(with camera) again and I would like to get same results in realtime as in my example 1). Is this even possible?</p>
			</div>
			</div>
				<textarea id = "speech-7848" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-7848">
					<img id="start_img-7848" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-7848">Comment</button>
			<br><div id = "ans-8646"  class = "post">
				<h2>Answer</h2>
			<div id="vote-8646" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">2</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>The problem you want to solve is definitely a SLAM problem and not just simply localization (or maybe we can consider it SLAm since the mapping part is not as heavy). The reason for this is that you will need to do some kind of mapping for initialization when you set up the environment. Of course you could set up the environment with markers or known features and carefully position them so that you know the map immediately, but that process is a lot harder than most people imagine.</p>

<p>Based on your question and the comments you've provided in CroCo's answer (which, by the way, is still a decent answer but I would like to expand), I see two paths that you can take which shouldn't be too difficult given all the resources available out there:</p>

<ol>
<li><p>Vision-based: Use <a href="https://www.google.ca/search?q=fiducial+markers&amp;safe=off&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0ahUKEwilvrrXp9DJAhXvq4MKHRKLBMsQ_AUIBygB&amp;biw=1536&amp;bih=692" rel="nofollow">fiduciary markers</a> (QR codes or typical black and white checker patterns like you see on crash-test dummies), then locate these markers using computer vision feature recognition algorithms (<a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_table_of_contents_feature2d.html" rel="nofollow">OpenCV can do this easily using something like SURF</a>). You can perform the initial mapping by using a <a href="http://www2.informatik.uni-freiburg.de/~stachnis/pdf/grisetti10titsmag.pdf" rel="nofollow">graph-based SLAM</a> approach (not real-time, record a bunch of data and crunch it all at once), then do localization only in real-time using a simplified <a href="https://en.wikipedia.org/wiki/Bundle_adjustment" rel="nofollow">bundle adjustment</a> approach (with just one single image and enough visible features).</p></li>
<li><p>LiDAR-based: Rely generally on <a href="https://en.wikipedia.org/wiki/Iterative_closest_point" rel="nofollow">ICP registration</a> with your reference point cloud (pre-built map) and a fresh scan from the sensor. Note that to do this you need to use a scanner on your stick instead of a camera. It will be almost impossible to build the map with laser scan data and then localize inside it with a camera. I say "almost" because there does exist a body of research that relies on monocular cameras for generating 3D data from 2D images (<a href="https://en.wikipedia.org/wiki/Photometric_stereo" rel="nofollow">shape from shading</a>, for example), but that is going to be a much bigger challenge than I suspect you want to tackle.</p></li>
</ol>

<p>Another interesting option is to use something like the X-Box Kinect (v1 or v2) so that you can get both 2D camera data and 3D scanning at the same time. With that approach you can then identify features in the camera images but have them linked to 3D coordinates in the scan data. <a href="https://www.youtube.com/watch?v=AMLwjo80WzI" rel="nofollow">Here</a> is an example of the Kinect being used for indoor SLAM.</p>

<p>Some of the challenges you will encounter will be motion blur and even rolling shutter issues if you are using a fast-moving camera point-of-view. Your problem could be solved simply by considering a new image, identifying the features in that image, and then simple camera 3D reconstruction (again using <a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_table_of_contents_calib3d/py_table_of_contents_calib3d.html" rel="nofollow">OpenCV's camera reconstruction tools</a> would be recommended).</p>

<p>I also suggest checking into using <a href="http://www.ros.org/" rel="nofollow">ROS</a>, which provides a lot of the components for solving your problem already built and ready for implementation using a variety of different sensors.</p>

<p>Another thing that you haven't mentioned (and is alluded to in CroCo's answer) is that you can use an IMU (integrated accelerometer, gyroscope, and possibly magnetometer) to provide motion estimates of the camera itself. This is not sufficient alone but can make real-time pose estimation much easier (actually, most of us would consider it crucial). With the use of an IMU and camera/scanner data, you can then use an EKF or particle filter as has been suggested.</p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-8646" data-toggle = "popover">
				<p>user name : Brian Lynch</p>
				<p> user reputation : 1237</p>
				<p class = "tagcontent" id = "usertaginfo-8646">{'None': 85}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-8646" class = 'collapse'>
			</div>
				<textarea id = "speech-8646" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-8646">
					<img id="start_img-8646" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-8646">Comment</button>
			</div>
			<div id = "resourcestab" class = "resourcestab">
				<ul class="nav nav-tabs">
					<li class="active"><a data-toggle="tab" href="#resources">Resources</a></li>
					<li><a data-toggle="tab" href="#summary">Summary</a></li>
				</ul>
					<div class="tab-content">
						<div id="resources" class="tab-pane fade in active">
							<h3>Resources</h3>
							<div id = "resourcescontent"></div>
						</div>
						<div id="summary" class="tab-pane fade">
							<h3>Summary</h3>
							<div id = "summarycontent"></div>
						</div>
			</div>
			</div>
			<footer>Moore & Peps collaboration.</footer>
	</div>
	<script src="/post.js"></script>
	<script type="text/javascript">
		$("#loginmodals").load("/loginModal.html");
		$("#issuemodals").load("/issueModal.html");
		$("#highlight_tool").load("/highlight_tool.html");
		checkLoggedInUser()
		var content = $('.content').html();
		populateResources(content)
		getHighlights()
		setOnLinksHover()
	</script>
	<script src="/media.js"></script>
	<script src="/vote.js"></script>
	<script src="/managefunction.js"></script>
	</body>
</html>