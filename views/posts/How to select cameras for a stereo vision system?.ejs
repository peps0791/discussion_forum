<html>
	<head>
		<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="  crossorigin="anonymous"></script>
		<script src = "/jquery-highlight.js"></script>
		<link href="/jquery.upvote.css" rel="stylesheet">
		<script src = "/jquery.upvote.js" type="text/javascript"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
		<link rel="stylesheet" href="/style.css"/>
		<script src="/createlinks.js"></script>
		<script src="/textaudit.js"></script>
		<script src="/PorterStemmer1980.min.js"></script>
		<script src="/highlight.js"></script>
		<title id = 'pagetitle'>How to select cameras for a stereo vision system?
		</title>
	</head>
	<body id = 'pagebody'>
		<div id = "loginmodals"></div>
		<div id = "issuemodals"></div>
		<div id = "highlight_tool"></div>
		<div id = "comment_tool"></div>
		<div class = "container">
			<header>
				<h1>Just Another Discussion Forum</h1>
			</header>
			<div class="topnav" id="myTopnav">
				<a href="/home">Home</a>
				<a href = "#issueModal" data-toggle="modal" style = "float:right">Report Issue</a>
			</div>
			<div class = "content">
			<div id = "ques-896" class = "post">
			<h2>Question</h2>
			<div id="vote-896" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">15</span>
				<a class="downvote"></a>
				<a class="star"></a>
				<p>Views :: 8856</p>
			</div>
			<form id = "questionpostsform" method="GET" action = "/ask">
				<input type="submit" id = "quesbtn" class="btn btn-primary btn-lg" value="Ask Question">
			</form>
				<h2>How to select cameras for a stereo vision system?</h2>
<p>I am in the process of building a stereo vision system to be used on a UGV. The system is for a robot that will be used in a competition wherein the robot is teleoperated to find relatively small colored rocks in a large outdoor field. I understand how to calibrate such a system and process the data for a stereo vision system. I do not however know how to select cameras for such a system. What are the best practices for picking cameras for a stereo vision system?</p>

			</div>
			<div class = "userinfosection"  id = "userinfo-896" data-toggle = "popover">
				<p>user name : DaemonMaker</p>
				<p> user reputation : 3321</p>
				<p class = "tagcontent" id = "usertaginfo-896">{'control': 4, 'stereo-vision': 15, 'None': 271, 'computer-vision': 15, 'battery': 7, 'cameras': 15, 'research': 4, 'troubleshooting': 7}</p>
			</div><br>
			<br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-896" class = 'collapse'>
			</div>
				<textarea id = "speech-896" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-896">
					<img id="start_img-896" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-896">Comment</button>

<h1>Answers</h1>
			<br><div id = "ans-899"  class = "post">
				<h2>Answer</h2>
			<div id="vote-899" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">6</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>You should start by calculating how many frames per second you need, and how much camera resolution you can process at that framerate.  If nothing else, that will prevent you from overspending or from buying a camera that won't suit your needs.  </p>

<p>Beyond that, there are a variety of features that make the choice more difficult/interesting.  Different cameras (especially network cameras like Axis) allow you to alter the image quality, or to specify a max bitrate for the image stream.  Some cameras also give you choices on the shutter speed, allowing you to favor a constant exposure time or a constant average illumination in the image.  Some cameras are more sensitive than others (the last time I worked with this was in 2009, and we noticed that the PS3 Eye did really well in low light conditions).  </p>

<p>Probably the best thing you can do would be to run your image processing algorithms on a few static images that you take with a DSLR, then attempt to reduce the frame size and quality to see where things begin to break down.  </p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-899" data-toggle = "popover">
				<p>user name : Ian</p>
				<p> user reputation : 9640</p>
				<p class = "tagcontent" id = "usertaginfo-899">{'planning': 10, 'None': 809, 'power': 1, 'algorithm': 10, 'battery': 1, 'slam': 7, 'coverage': 10, 'mobile-robot': 9, 'sensors': 9}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-899" class = 'collapse'>
			</div>
				<textarea id = "speech-899" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-899">
					<img id="start_img-899" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-899">Comment</button>
			<br><div id = "ans-901"  class = "post">
				<h2>Answer</h2>
			<div id="vote-901" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">6</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>A few things you should be on the lookout for:</p>

<ul>
<li><strong>Global shutter</strong> basically means all pixels get captured at the same time, as opposed to Rolling shutter where they are captured sequentially in a line scan fashion. Since your UGV will be moving around and performing stereo algorithms over the images you capture, it could be important that you avoid aberrations that occure when camera move, such as the ones seen in the pictures below (taken from <a href="http://en.wikipedia.org/wiki/Rolling_shutter" rel="nofollow noreferrer">Wikipedia</a>):</li>
</ul>

<p><a href="https://i.stack.imgur.com/u8yKF.jpg" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/u8yKFm.jpg" alt="Moving car taken with CMOS camera phone exhibits skew"></a>
<a href="https://i.stack.imgur.com/EVM6g.jpg" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/EVM6gm.jpg" alt="A photo exhibiting partial exposure. Lighting conditions changed between the exposure of the top and bottom parts of the photo."></a>
<a href="https://i.stack.imgur.com/Q6NJX.jpg" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/Q6NJXm.jpg" alt="A shot of a turboprop propeller"></a></p>

<ul>
<li><p><strong>Camera synchronization</strong> in hardware is achievable by some cameras, notably firewire cameras AFAIK. That can greatly improve the results for stereo when things are moving around.</p></li>
<li><p><strong>Mounting</strong> should be done in a way that changes in the extrinsic parameters (the relative pose between cameras) for the stereo pair will be unlikely to change after calibration. In your rig that might be more important, since the UGV might face uneven terrain outdoors and things will vibrate.</p></li>
<li><p><strong>Dedicated stereo hardware</strong> makes it possible to acquire disparity images directly as output of your stereo vision system, which eases the load off your embedded computing. It also tends to be much faster than running the very same algorithms in software.</p></li>
</ul>

<p>As usual, the more you're willing to pay the better the results. To be honest, if you're able to buy a full-blown stereo camera such as the <a href="http://www.ptgrey.com/products/bumblebee2/bumblebee2_stereo_camera.asp" rel="nofollow noreferrer">Bumblebee2</a>, that's what I'd do. Otherwise, if you're on the cheaper side, I would simply go with a <a href="http://www.xbox.com/en-US/kinect" rel="nofollow noreferrer">Kinect</a>: it's unlikely you'll be able to get a system that outperforms it for the same price.</p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-901" data-toggle = "popover">
				<p>user name : georgebrindeiro</p>
				<p> user reputation : 1266</p>
				<p class = "tagcontent" id = "usertaginfo-901">{'computer-vision': 9, 'None': 98, 'slam': 9}</p>
			</div><br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-901">Load Comments</button></br>
			<div id = "commentsection-901" class = 'collapse'>
			<div id = "comment-2231" class = "comment">
				<p>The question was for an outdoor system. This effectively rules out the Kinect. Also, the algorithms that come with the Bumblebee are far from optimal, we found.</p>
			</div>
			<div id = "comment-2232" class = "comment">
				<p>I'm with you on the Kinect comment, but can't the stereo algorithms that come with the Bumblebee be substituted with your own code? The biggest advantage I was pointing out was in the actual hardware, not the software that is bundled with it.</p>
			</div>
			<div id = "comment-2233" class = "comment">
				<p>yes that is true. You can use it just like two normal cameras, and it has the advantage of a rigid housing.</p>
			</div>
			<div id = "comment-2234" class = "comment">
				<p>not only that but global shutter, good lenses and other goodies</p>
			</div>
			</div>
				<textarea id = "speech-901" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-901">
					<img id="start_img-901" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-901">Comment</button>
			<br><div id = "ans-927"  class = "post">
				<h2>Answer</h2>
			<div id="vote-927" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">10</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>Off the top of my head I would go by the following selection criteria</p>

<ul>
<li>color/b&amp;w - usually b&amp;w is better, since the stereo algorithms only use one channel anyway</li>
<li>baseline - this really depends on the scene. With the baseline you control how much accuracy you get with distance. Wider baseline results in higher disparity values and thus less noise on the distance estimation. Higher baseline also means that you will get a reduced overlap between your field of views. Most importantly though, the wider the baseline the harder the matching between the two views. So the quality of the result goes down.</li>
<li>shutter - always use a global shutter for anything with computer vision on mobile robots</li>
<li>resolution - most stereo algorithms are computationally expensive. And you will likely not need that many 3d points. In the near field the sampling density is usually enough, and the far field your error from the low disparity is more of a problem than sampling density. 640x480 is fine in most cases. Some chips have a wider aspect ratio, which is favourable for the overlap, but you can get the same with using a sub-window of your chip.</li>
<li>objectives/field of view - for mobile outdoor robots I prefer a wide field of view over narrow objectives. More or less for the same reasons as the resolution. Make sure your objectives are rigid and have a means to fixate any moving parts e.g. like adjustable focal length. In most cases a fixed focal length is fine anyway, since you are limited by the selection of your baseline.</li>
<li>trigger - when you create your own stereo rig, your cameras should support hardware trigger and ideally one should trigger the other.</li>
<li>framerate - In my opinion the least important consideration. Unless you have a lot of processing power you won't be getting much more than something like 5 Hz anyway. So your algorithm is much more likely to be the bottleneck, rather than the chip or the connection.</li>
<li>interface - Most cameras come with Firewire/USB2/USB3/Ethernet. USB2 is useless as it consumes a lot of CPU. Firewire is good if you have a port, but I think it seems to be on the decline in favour of USB3 these days. Didn't have much experience with USB3 yet. Ethernet is quite nice because you are more likely to find embedded systems with GigEthernet than USB3 at the moment.</li>
<li>housing - as rigid as possible. Recalibrating is an annoying procedure.</li>
</ul>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-927" data-toggle = "popover">
				<p>user name : Jakob</p>
				<p> user reputation : 2519</p>
				<p class = "tagcontent" id = "usertaginfo-927">{'ransac': 3, 'None': 210, 'computer-vision': 1, 'cameras': 1, 'c++': 3, 'slam': 12, 'rock': 1, 'i2c': 3, 'servos': 3, 'software': 1}</p>
			</div><br><h3>Comments</h3><p>no comments yet<p><br>
			<div id = "commentsection-927" class = 'collapse'>
			</div>
				<textarea id = "speech-927" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-927">
					<img id="start_img-927" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-927">Comment</button>
			<br><div id = "ans-938"  class = "post">
				<h2>Answer</h2>
			<div id="vote-938" class="upvote" style="float:left;">
				<a class="upvote"></a>
				<span class="count">4</span>
				<a class="downvote"></a>
				<a class="star"></a>
			</div>
				<p><p>That is an interesting topic, and not very easy to get right on the first try. From experience with this, here are the most important things. </p>

<ul>
<li><p><strong>Synchronization</strong>. The camera must be 100% synced. For example, say the UGV is driving at a modest 36Km/hr (10m/s)  and recording frames at 30 frames per second. That is, at every frame the UGV would cover 3m. Now, say your sync is off by 1ms, one of the cameras will be off by ~0.3m, which is bad [just off the top of my head]. Sync problems are very hard to detect.</p></li>
<li><p><strong>Resolution</strong>. In the context of stereo, we refer to depth resolution, or how much depth can we resolve given a change in disparity. An excellent explanation can be found here <a href="http://pub1.willowgarage.com/~konolige/svs/disparity.htm" rel="nofollow">http://pub1.willowgarage.com/~konolige/svs/disparity.htm</a> The equation you want to look at is a function of the focal length of the image and the stereo baseline. $\delta Z = \frac{Z^2}{Bf}\delta d$. This says that depth resolving power $\delta Z$ is inversely proportional to the baseline $B$ times the focal length $f$. That is the longer the baseline, the smaller $\delta Z$, the better. Meaning, you can resolve more depth. The minimum change in disparity $\delta d$ is controlled partially by the image resolution and the algorithm used. For your calculations, you can safely assume that $\delta d$ is at least $1/2$. It is better to be conservative with the choice of $\delta d$.</p></li>
<li><p><strong>Overlap</strong>. You want to have overlap between the cameras to get stereo. Hence, you need to choose a combination of lens focal length (field of view) and baseline so that you have enough overlap for the application. Basically, trigonometry work on the board, or a quick matlab/python script.</p></li>
</ul>

<p>For UGV's, there are two uses for stereo. </p>

<ol>
<li><p><strong>Navigation and Pose Estimation</strong> In this case you most probably need a large baseline + long focal length. This allows the stereo to see and resolve depth better and longer range.</p></li>
<li><p><strong>Obstacle detection and avoidance</strong> You will probably need a shorter baseline and wider lens (smaller focal length) so that  you can focus on things very close to you. </p></li>
</ol>

<p>Some UGV's might have both stereo setups, the large baseline narrow field of view for navigation and another one or two for obstacle avoidance. </p>

<p>Be very careful what you buy. Some companies offer already built stereo setups. Those are great on the robustness side of things, they don't loose calibration easily and are always in sync. The problem is that the commercially available ones have a small baseline. If you want to build your own. I'm guessing you will end up doing so, make sure the camera are <em>syncable</em>. Firewire is great for this, two camera on the same bus will sync with 125microsecond accuracy out of the box! USB and Gige cams are painful to sync.  When you put everything together, you want to make sure that the lenses are not going to move at all, and the baseline is rigid, very rigid for the application. </p>

<p>Also be careful in lens selection. Not all lenses work with all cameras. Lenses have a resolution too. This is a another topic, here is a short article on this <a href="http://www.qualitymag.com/articles/90642-q-a--selecting-lenses-for-machine-vision-systems" rel="nofollow">http://www.qualitymag.com/articles/90642-q-a--selecting-lenses-for-machine-vision-systems</a></p>
</p><br>
			</div>
			<div class = "userinfosection"  id = "userinfo-938" data-toggle = "popover">
				<p>user name : bendervader</p>
				<p> user reputation : 197</p>
				<p class = "tagcontent" id = "usertaginfo-938">{'None': 8}</p>
			</div><br><h3>Comments</h3>
				<button data-toggle = 'collapse' data-target = "#commentsection-938">Load Comments</button></br>
			<div id = "commentsection-938" class = 'collapse'>
			<div id = "comment-6966" class = "comment">
				<p>Your synchronization computation is wrong. 30 FPS at 10m/s gives a distance of 33cm (not 3m) per frame. Also 1ms at this speed means distance of 1cm (regardless of FPS). So synchronization on ms level is a super result actually for such speeds!</p>
			</div>
			</div>
				<textarea id = "speech-938" rows="3" cols="80"></textarea><br>
				<button class="record-start" id="start-938">
					<img id="start_img-938" src="/mic.gif" alt="Start">
				</button>
				<button class = "comment-btn" id = "comment-btn-938">Comment</button>
			</div>
			<div id = "resourcestab" class = "resourcestab">
				<ul class="nav nav-tabs">
					<li class="active"><a data-toggle="tab" href="#resources">Resources</a></li>
					<li><a data-toggle="tab" href="#summary">Summary</a></li>
					<li><a data-toggle="tab" href="#highlights">Highlights</a></li>
				</ul>
					<div class="tab-content">
						<div id="resources" class="tab-pane fade in active">
							<h3>Links from the Page</h3>
							<div id = "resourcescontent"></div>
						</div>
						<div id="summary" class="tab-pane fade">
							<h3>Summary</h3>
							<div id = "summarycontent"></div>
						</div>
						<div id="highlights" class="tab-pane fade">
							<h3>Highlights</h3>
							<div id = "highlightcontent"></div>
						</div>
			</div>
			</div>
			<footer>Moore & Peps collaboration.</footer>
	</div>
	<script src="/post.js"></script>
	<script type="text/javascript">
		$("#loginmodals").load("/loginModal.html");
		$("#issuemodals").load("/issueModal.html");
		$("#highlight_tool").load("/highlight_tool.html");
		$("#comment_tool").load("/comment_tool.html");
		checkLoggedInUser()
		var content = $('.content').html();
		populateResources(content)
		getHighlights()
		setOnLinksHover()
	</script>
	<script src="/media.js"></script>
	<script src="/vote.js"></script>
	<script src="/managefunction.js"></script>
	</body>
</html>